---
title: "Лабораторная работа № 7"
output:
  html_document:
    df_print: paged
---

```{r}
library(keras) # чтобы не отображать результат написать после r.. eval=FALSE
library(dplyr)
library(glue)
library(tidyverse)
train_dir <- file.path("data/dogs-vs-cats/train")
test_dir <- file.path("data/dogs-vs-cats/test")
# create train, validation, and test file paths for cat images
train_cats_dir <- file.path(train_dir, "cats")
test_cats_dir <- file.path(test_dir, "cats")

# create train, validation, and test file paths for dog images
train_dogs_dir <- file.path(train_dir, "dogs")
test_dogs_dir <- file.path(test_dir, "dogs")

```

---
1. Случайное вращение
---

Вращение изображения является одним из широко используемых методов увеличения и позволяет модели стать инвариантной к ориентации объекта.

Image_Data_Generator позволяет случайным образом поворачивать изображения на любой градус от 0 до 360, предоставляя целочисленное значение в аргументе rotate_range.

Когда изображение поворачивается, некоторые пиксели перемещаются за пределы изображения и оставляют пустую область, которую необходимо заполнить. Можно заполнить это различными способами, например, постоянным значением или ближайшими значениями пикселей и т. д. Это указывается в аргументе fill_mode и значением по умолчанию является «ближайший» (nearest), который просто заменяет пустую область ближайшими значениями пикселей.

Подготовим картинку.

```{r}
fnames_tcat<- list.files(train_cats_dir, full.names = TRUE) #список файлов в директории
img_path<- fnames_tcat[[15]] # выберем 1 картинку под индексом 15, например
img<- image_load(img_path, target_size = c(300,300))
# преобразуем в тензор
img_array<- array_reshape(image_to_array(img), c(1, 300, 300, 3))
```

Теперь запустим преобразование.

```{r}
datagen <- image_data_generator(rescale = 1/255, rotation_range = 190,fill_mode = "nearest" )
# rescale используется для перемасштабирования даннхы пикселей из 0-255 в 0-1, что является по сути своей нормализацией
aug_iter<- flow_images_from_data(img_array, generator = datagen, 
                                 batch_size = 1)
# batch_size используется здесь для разбиения изображения на равное количество изображений, в данном случае м этого не делаем
axs<- par(mfrow = c(3,1), pty = 's')
for (i in 1:3) {
  batch<- generator_next(aug_iter)
  plot(as.raster(batch[1,,,]))
}

```

---
2. Случайный сдвиг 
---

Может случиться так, что объект не всегда может находиться в центре изображения. Чтобы преодолеть эту проблему, мы можем сместить пиксели изображения либо по горизонтали, либо по вертикали; это делается путем добавления определенного постоянного значения ко всем пикселям.

Image_Data_Generator имеет аргумент **height_shift_range** для вертикального сдвига изображения и **width_shift_range** для горизонтального сдвига изображения. Если значение является числом с плавающей точкой, это будет означать процент ширины или высоты смещаемого изображения. В противном случае, если это целое значение, то просто ширина или высота смещаются этими многими значениями пикселей.

```{r}
datagen <- image_data_generator(rescale = 1/255, width_shift_range=0.2, height_shift_range=0.2)
aug_iter<- flow_images_from_data(img_array, generator = datagen, 
                                 batch_size = 1)
axs<- par(mfrow = c(3,2), pty = 's')
for (i in 1:6) {
  batch<- generator_next(aug_iter)
  plot(as.raster(batch[1,,,]))
}
```

---
3. Случайный переворот
---

Переворачивание изображений также является отличной техникой дополнения, и имеет смысл использовать ее с большим количеством различных объектов.

Параметры **horizontal_flip** и **vertical_flip** для переворачивания вдоль вертикальной или горизонтальной оси. Эта техника должна соответствовать объекту на изображении. То есть не противоречить смыслу исследования.

```{r}
datagen <- image_data_generator(rescale = 1/255, horizontal_flip=T, vertical_flip=T)
aug_iter<- flow_images_from_data(img_array, generator = datagen, 
                                 batch_size = 1)
axs<- par(mfrow = c(3,1), pty = 's')
for (i in 1:3) {
  batch<- generator_next(aug_iter)
  plot(as.raster(batch[1,,,]))
}
```

---
4. Случайная яркость
---

Случайным образом изменяет яркость изображения. Это также очень полезная техника дополнения, потому что большую часть времени наш объект не будет находиться в идеальных условиях освещения.

Яркостью можно управлять с помощью аргумента **brightness_range**. Он принимает список из двух значений с плавающей точкой и выбирает значение сдвига яркости из этого диапазона. Значения менее 1,0 затемняют изображение, тогда как значения выше 1,0 осветляют изображение.

```{r}
datagen <- image_data_generator(rescale = 1/255, brightness_range=(0.4:1.5))
aug_iter<- flow_images_from_data(img_array, generator = datagen, 
                                 batch_size = 1)
axs<- par(mfrow = c(3,1), pty = 's')
for (i in 1:3) {
  batch<- generator_next(aug_iter)
  plot(as.raster(batch[1,,,]))
}
```

---
4. Случайный масштаб
---

Увеличение масштаба либо случайным образом увеличивает изображение, либо уменьшает изображение. Принимает значение float для масштабирования аргумента **zoom_range**. Можно предоставить список с двумя значениями, указывающими нижний и верхний предел. В противном случае, если указать значение float, то масштабирование будет выполнено в диапазоне [1-zoom_range,1+zoom_range].

```{r}
datagen <- image_data_generator(rescale = 1/255, zoom_range = 0.3)
aug_iter<- flow_images_from_data(img_array, generator = datagen, 
                                 batch_size = 1)
axs<- par(mfrow = c(3,1), pty = 's')
for (i in 1:3) {
  batch<- generator_next(aug_iter)
  plot(as.raster(batch[1,,,]))
}
```

---
5. Оптимальные параметры
---

Оптимальные параметры, вероятно, должны подбираться исходя из объектов исследования. В частности, в нашем примере вероятно нет смысла использовать перемасштабирвоание, т.к. форма животных в действительности не должна быть сплюченной или расплющенной.

Все остальные преобразования имеют место быть. Пример:

```{r}
datagen <- image_data_generator(rescale = 1/255, rotation_range = 140,  
                                width_shift_range = (0.2:0.9),
                                height_shift_range = (0.2:0.9), 
                                shear_range = (0.2:0.9), 
                                brightness_range=(0.4:1.5), 
                                horizontal_flip = T, vertical_flip = T, 
                                fill_mode = "nearest")
aug_iter<- flow_images_from_data(img_array, generator = datagen, 
                                 batch_size = 1)
axs<- par(mfrow = c(3,3), pty = 's')
for (i in 1:12) {
  batch<- generator_next(aug_iter)
  plot(as.raster(batch[1,,,]))
}
```

---
6. Метод flow_images_from_data()
---

Метод **flow_images_from_data()** позволяет считывать изображения непосредственно из меток и дополнять их, пока модель нейронной сети обучается.

```{r}
# Загрузка данных 2 категорий
fnames_tdog<- list.files(train_dogs_dir, full.names = TRUE)
img_path_cats<- fnames_tcat[60:69] 
img_path_dogs<- fnames_tdog[60:69]
img_path<- c(img_path_cats, img_path_dogs)

loadpics = function(filenames) {
  a = lapply(filenames, image_load, target_size = c(100,100))
  b = lapply(a, image_to_array)
  c = lapply(b, array_reshape, dim = c(100, 100, 3))
  d = normalize(c, axis = 1)
  return(d)
  }

trainx = loadpics(img_path) 
trainlabel = to_categorical(c(1, 1,1,1,1,1,1,1,1,1, 0, 0,0,0,0,0,0,0,0,0))

# Формирование набора из 2 изображений каждого класса

train_generator <- flow_images_from_data(x = trainx, y = trainlabel,
    datagen, batch_size = 20)
batch <- generator_next(train_generator)
str(batch)
```

Построим так же тестовую выборку.

```{r}
img_path_cats<- fnames_tcat[80:89] 
img_path_dogs<- fnames_tdog[80:89]
img_path<- c(img_path_cats, img_path_dogs)
testx = loadpics(img_path) 
testlabel = trainlabel
```

Теперь построим сверточную нейронную сеть.

CNN будет включать в себя:

-   5 последовательных слоя conv и max pooling;

-   Нормализующие слои;

-   Сглаживание слоя;

-   Дропаут-слои для исключения переобучения;

-   Сеть с плотным подключением;

-   Один двоичный выход.

```{r}
cnn <- keras_model_sequential() %>%
    layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu",
        input_shape = c(100, 100, 3)) %>% 
  layer_batch_normalization()%>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), padding = 'Same',
                activation = 'relu')%>%
  layer_batch_normalization()%>%
  layer_max_pooling_2d(pool_size = c(2, 2))%>%
  layer_dropout(rate = 0.2) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3,3),padding = 'Same',
                activation = 'relu')%>%
  layer_batch_normalization()%>%
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  layer_conv_2d(filters = 64, kernel_size = c(2, 2), activation = "relu") %>% 
  layer_dropout(rate = 0.2) %>%
  layer_flatten() %>%
  layer_dense(units=1024,activation='relu')%>%
  layer_dense(units=512,activation='relu')%>%
  layer_dense(units=256,activation='relu')%>%
  layer_dense(units = 2, activation = "softmax")
cnn %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_adam(),
  metrics = keras$metrics$AUC()
)

summary(cnn)
```

Запустим и построим модель.

```{r}
history_cnn <- cnn %>%
    fit(train_generator, epochs = 20,
        verbose = 0)
plot(history_cnn)
```

```{r}
cnn %>%
    keras::evaluate(testx, testlabel)
```

Оценки успешности классификации оставляют желать лучшего. Изменим аугментацию картинок таким образом, чтобы модель стала работать лучше. Ниже представлена результирующая модель.

```{r}
datagen <- image_data_generator(
  featurewise_center = F,
  samplewise_center=F,
  featurewise_std_normalization = F,
  samplewise_std_normalization=F,
  zca_whitening=F,
  horizontal_flip = F,
  vertical_flip = F,
  width_shift_range = 0.15,
  height_shift_range = 0.15,
  rotation_range = 0.15,
  shear_range = 0.15)
train_generator <- flow_images_from_data(x = trainx, y = trainlabel,
    datagen, batch_size = 128)
# Определим так же тестовые данные для проверки сети:
valid_generator <- flow_images_from_data(x = testx, y = testlabel,
    datagen, batch_size = 128)
```

```{r}
history_cnn <- cnn %>%
    fit_generator(train_generator, steps_per_epoch = 1, epochs = 10, 
                  validation_data = valid_generator)
plot(history_cnn) + 
  scale_x_continuous(limits = c(0, length(history_cnn$metrics$val_loss)))
```

Сохраним полученную модель

```{r}
cnn %>% save_model_hdf5("cats_and_dogs.h5")
```
